#!/usr/bin/env python

# Transforms movie data it into a collaborator's graph. Network metrics are
# calculated for each movie, and are recorded for further analysis.

# Standard libs.
import os
import sys
import pickle
import logging
from inspect import getmembers, isfunction
from datetime import datetime

# 3rd party libs.
from tqdm import tqdm
from pymongo import MongoClient

# This package.
from teamspector import network, metrics
from teamspector.datasets.imdbws.experiments import experiments

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__file__.split("/")[-1])

db = MongoClient().imdbws

EXP = experiments[sys.argv[1] if len(sys.argv) > 1 else 0]


def build_team(mov, specs):
    """
    Given a movie record and a list of valid roles, return a list of unique ids
    of team members that match any of the given roles.
    """
    team = set()
    for spec in specs:
        if(spec in ['writer', 'director'] and mov.get(spec + 's')):
            for agent in mov[spec + 's']:
                if agent not in team:
                    team.add(agent)

        matches = lambda p: p['job'] == spec or p['category'] == spec
        for agent in filter(matches, mov['principals']):
            if agent['nconst'] not in team:
                team.add(agent['nconst'])

    return tuple(team) if len(team) > 1 else None


def load_components_cache(year):
    """
    Load a list of components at a given year, along with all movies that were
    added to the giant component that year and their respective teams.
    """
    fname = f"cache/comp_{EXP['id']}_{year}.p"
    logger.info(f"Getting components cache (experiment {EXP['id']}, {year}).")
    if(os.path.isfile(fname)):
        return pickle.load(open(fname, 'rb'))
    return None


def save_components_cache(year, components, movies_to_process):
    """
    Saves a list of components at a given year, along with all movies that were
    added to the giant component that year and their respective teams.
    """
    logger.info(f"Saving components cache (experiment {EXP['id']}, {year}).")
    fname = f"cache/comp_{EXP['id']}_{year}.p"
    pickle.dump((components, movies_to_process), open(fname, 'wb'))


def describe_components(components):
    """Logs information about the current state of the components."""
    if components:
        huge_comp = len(components[0])
        all_comps = huge_comp + sum([len(c) for c in components[1:]])
        x = 100 * (float(huge_comp) / all_comps)
        logger.info(f"There are {len(components)} components.")
        logger.info(f"Huge component has {huge_comp} nodes, {x:.2f}% of all.")


def process_movies(components, year):
    cache = load_components_cache(year)
    date = datetime(year, 1, 1)
    if cache:
        components, movies_to_process = cache
    else:
        movies_to_process = []

        qry = dict(EXP['filter'], startYear={'$eq': year})
        cursor = db.titles.find(qry, no_cursor_timeout=True)
        movies = list(cursor.sort([('_id', 1)]).batch_size(0))

        components = network.prune_components(components, date)
        for mov in tqdm(movies):
            team = build_team(mov, EXP['team'])
            if team:
                giant = network.update_components(components, team, mov['_id'], date)
                if giant:
                    movies_to_process.append((mov['_id'], team))

        save_components_cache(year, components, movies_to_process)

    describe_components(components)

    if year < EXP['year_start']:
        return components

    for mov, team in tqdm(movies_to_process):
        target = db[f"exp_{EXP['id']}"]
        if(target.find_one({'_id': mov})):
            continue

        mov = db.titles.find_one({'_id': mov})
        H = components[0]

        logger.debug(f"Calculating ego for {mov['primaryTitle']}.")
        pair_agg = metrics.calc_ego(H, team, year, EXP['filter'])
        logger.debug(f"Calculating pair metrics for {mov['primaryTitle']}.")
        pair_agg = metrics.calc_pair(H, team)
        logger.debug(f"Calculating team metrics for {mov['primaryTitle']}.")
        team_metrics = metrics.calc_team(H, team, year, EXP['filter'])
        logger.debug(f"Aggregating metrics for {mov['primaryTitle']}.")

        exp = {'title': mov['primaryTitle'],
               'year': year,
               'ypct': mov['ypct'],
               'ypct_votes': mov['ypct'],
               'ypct_rating': mov['ypct'],
               'top100': mov['top100']}

        exp.update(team_metrics)
        exp.update(ego_agg)
        exp.update(pair_agg)

        target = db[f"exp_{EXP['id']}"]
        target.update_one({'_id': mov['_id']}, {'$set': exp}, upsert=True)

    return components


cache = load_components_cache(EXP['year_start'] - 1)
if cache:
    components, _ = cache
    year = EXP['year_start']
else:
    logger.info(f"Bootstrapping components for experiment {EXP['id']}.")
    logger.debug(f"Finding earliest movie in the dataset.")
    earliest = db.titles.find_one(EXP['filter'], sort=[('startYear', 1)])
    year = earliest['startYear']
    components = []

while(year <= EXP['year_end']):
    logger.info(f"Processing movies from {year}.")
    components = process_movies(components, year)
    year += 1
